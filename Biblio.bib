@online{NInka2021Gan,
  author = {Nathan Inkawhich},
  title = {{PyTorch Documentation } DCGAN Faces Tutorial},
  year = 2021,
  url = {https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html},
  urldate = {2021-18-10}
}

@article{Krizhevsky2009,
title= {CIFAR-10 (Canadian Institute for Advanced Research)},
journal= {},
author= {Alex Krizhevsky and Vinod Nair and Geoffrey Hinton},
year= {2009},
url= {http://www.cs.toronto.edu/~kriz/cifar.html},
abstract= {The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images. 

The dataset is divided into five training batches and one test batch, each with 10000 images. The test batch contains exactly 1000 randomly-selected images from each class. The training batches contain the remaining images in random order, but some training batches may contain more images from one class than another. Between them, the training batches contain exactly 5000 images from each class. },
keywords= {Dataset},
terms= {}
}

@article{Constatantin2020,
author = {Constantin, Mihai Gabriel and Redi, Miriam and Zen, Gloria and Ionescu, Bogdan},
title = {Computational Understanding of Visual Interestingness Beyond Semantics: Literature Survey and Analysis of Covariates},
year = {2019},
issue_date = {March 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {52},
number = {2},
issn = {0360-0300},
url = {https://doi.org/10.1145/3301299},
doi = {10.1145/3301299},
abstract = {Understanding visual interestingness is a challenging task addressed by researchers in various disciplines ranging from humanities and psychology to, more recently, computer vision and multimedia. The rise of infographics and the visual information overload that we are facing today have given this task a crucial importance. Automatic systems are increasingly needed to help users navigate through the growing amount of visual information available, either on the web or our personal devices, for instance by selecting relevant and interesting content. Previous studies indicate that visual interest is highly related to concepts like arousal, unusualness, or complexity, where these connections are found based on psychological theories, user studies, or computational approaches. However, the link between visual interestingness and other related concepts has been only partially explored so far, for example, by considering only a limited subset of covariates at a time. In this article, we present a comprehensive survey on visual interestingness and related concepts, aiming to bring together works based on different approaches, highlighting controversies, and identifying links that have not been fully investigated yet. Finally, we present some open questions that may be addressed in future works. Our work aims to support researchers interested in visual interestingness and related subjective or abstract concepts, providing an in-depth overlook at state-of-the-art theories in humanities and methods in computational approaches, as well as providing an extended list of datasets.},
journal = {ACM Comput. Surv.},
month = {mar},
articleno = {25},
numpages = {37},
keywords = {complexity, humour, affective value and emotions, visual composition and stylistic attributes, memorability, aesthetic value, urban perception, social interestingness, Interestingness, saliency, creativity, coping potential, novelty}
}




@report{Krizhevsky2009a,
    author = {Alex Krizhevsky},
    title = {Learning Multiple Layers of Features from Tiny Images},
    institution = {Canadian Institute For Advanced Research},
    url = {https://www.cs.toronto.edu/~kriz/learning-features-2009-TR.pdf},
    year = 2009,
}



@online{Brendel2021,
  author = {Debbi Brendel},
  title = {lift-off in less than a second },
  year = 2021,
  url = {https://www.dpchallenge.com/image.php?IMAGE_ID=1266191},
  urldate = {2021-13-12}
}


@online{Mapplethorp1980,
  author = {Robert Mapplethorpe},
  title = {Self Portrait},
  year = 1980,
  url = {https://www.moma.org/collection/works/192666},
  urldate = {2021-13-12}
}

@online{Cannon2019,
author = {Cannon Inc.},
title = {The Principals of Tilt and Shift on TS-E lenses
},
year = 2019,
url = {https://support.usa.canon.com/kb/index?page=content&id=ART174524},
urldate = {2021-13-12}
}

@misc{lin2018focal,
      title={Focal Loss for Dense Object Detection}, 
      author={Tsung-Yi Lin and Priya Goyal and Ross Girshick and Kaiming He and Piotr Doll√°r},
      year={2018},
      eprint={1708.02002},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      urldate = {2021-18-10}
}


@online{Torch2021Trans,
  author = {Torch Contributors},
  title = {{PyTorch Documentation } Torchvision, Transforms},
  year = 2021,
  url = {https://pytorch.org/vision/stable/transforms.html},
  urldate = {2021.18.10}
}

@online{Snow2017,
  author = {Jackie Snow},
  title = {This AI Can Spot Art Forgeries by Looking at One Brushstroke},
  year = 2017,
  url = {https://www.technologyreview.com/2017/11/21/105077/this-ai-can-spot-art-forgeries-by-looking-at-one-brushstroke/},
  urldate = {2021.18.10}
}

@online{Car2017focal,
  author = {Carwin Avatar},
  title = {{Focal Loss for Dense Object Detection in PyTorch} Github Code},
  year = 2017,
  url = {https://github.com/clcarwin/focal_loss_pytorch},
  urldate = {2021/18/10}
}



@online{AVA2012,
  author = {Murray, Naila and Marchesotti, Luca and Perronnin, Florent},
  title = {{AVA: A large-scale database for aesthetic visual analysis}},
  year = 2021,
  url = {https://ieeexplore.ieee.org/document/6247954/citations#citations},
  urldate = {2021/14/10}
}

@online{guru,

url={https://gurushots.com/},
urldate = {2021/14/10},
 year = 2021,

}

@book{gonzalez2008digital,
  abstract = {Completely self-contained-and heavily illustrated-this introduction to basic concepts and methodologies for digital image processing is written at a level that truly is suitable for seniors and first-year graduate students in almost any technical discipline. The leading textbook in its field for more than twenty years, it continues its cutting-edge focus on contemporary developments in all mainstream areas of image processing-e.g., image fundamentals, image enhancement in the spatial and frequency domains, restoration, color image processing, wavelets, image compression, morphology, segmentation, image description, and the fundamentals of object recognition. It focuses on material that is fundamental and has a broad scope of application.},
  added-at = {2014-07-10T10:50:48.000+0200},
  address = {Upper Saddle River, N.J.},
  author = {Gonzalez, Rafael C. and Woods, Richard E.},
  biburl = {https://www.bibsonomy.org/bibtex/2bd73f6e1350f31aa5da16268e2b1e694/alex_ruff},
  description = {Digital Image Processing (3rd Edition): Rafael C. Gonzalez, Richard E. Woods: 9780131687288: Amazon.com: Books},
  interhash = {74494247f343d0cedb198c4b4f0c31eb},
  intrahash = {bd73f6e1350f31aa5da16268e2b1e694},
  isbn = {9780131687288 013168728X 9780135052679 013505267X},
  keywords = {book image_processing},
  publisher = {Prentice Hall},
  refid = {137312858},
  timestamp = {2014-07-10T10:50:48.000+0200},
  title = {Digital image processing},
  url = {http://www.amazon.com/Digital-Image-Processing-3rd-Edition/dp/013168728X},
  year = 2008
}


@electronic{szeliski2011computer,
  added-at = {2012-10-25T12:42:36.000+0200},
  address = {London; New York},
  author = {Szeliski, Richard},
  biburl = {https://www.bibsonomy.org/bibtex/2f58160db2b03916db911241ed09e2685/daill},
  description = {Computer Vision},
  interhash = {52bc88936329fd66b2af28d393532e40},
  intrahash = {f58160db2b03916db911241ed09e2685},
  isbn = {9781848829343 1848829345 9781848829350 1848829353},
  keywords = {computer vision},
  publisher = {Springer},
  refid = {682910466},
  timestamp = {2012-10-25T12:42:36.000+0200},
  title = {Computer vision algorithms and applications},
  url = {http://dx.doi.org/10.1007/978-1-84882-935-0},
  year = 2011
}

@book{Kodak1995take,
  title={How to Take Good Pictures: A Photo Guide by Kodak},
  author={Company, E.K. and Press, S.P.},
  isbn={9780345397102},
  lccn={95094477},
  url={https://books.google.co.uk/books?id=xv\_6nyTomPoC},
  year={1995},
  publisher={Ballantine Books}
}

@book{Kreiman2021, 
place={Cambridge}, 
title={Biological and Computer Vision}, 
DOI={10.1017/9781108649995}, 
publisher={Cambridge University Press}, 
author={Kreiman, Gabriel}, 
year={2021}
}

@book{Burke1773philosophical,
  title={A Philosophical Enquiry Into the Origin of Our Ideas of the Sublime and Beautiful},
  author={Burke, E.},
  url={http://209.85.147.99/books?id=abYPAAAAQAAJ},
  year={1773},
  publisher={J. Dodsley}
}

@book{Kant1892kant,
  title={Kant's Critique of Judgement},
  author={Kant, I. and Bernard, J.H.},
  url={https://books.google.co.uk/books?id=TajYzQEACAAJ},
  year={1892},
  publisher={Macmillan}
}

@Book{morris2004computer,
 author = {Morris, Tim},
 title = {Computer vision and image processing},
 publisher = {Palgrave Macmillan},
 year = {2004},
 address = {Basingstoke},
 isbn = {978-0333994511}
 }
 
 @book{d2018handbook,
  title={Handbook of Research on Form and Morphogenesis in Modern Architectural Contexts},
  author={D'Uva, Domenico},
  year={2018},
  publisher={IGI Global}
}
@book{russell2016artificial,
  title={Artificial Intelligence: a modern approach},
  author={Russell, Stuart J. and Norvig, Peter},
  edition={3},
  year={2009},
  publisher={Pearson}
}
@book{Sutton2018,
  added-at = {2019-07-13T10:11:53.000+0200},
  author = {Sutton, Richard S. and Barto, Andrew G.},
  biburl = {https://www.bibsonomy.org/bibtex/2f46601cf8b13d39d1378af0d79438b12/lanteunis},
  edition = {Second},
  interhash = {ac6b144aaec1819919a2fba9f705c852},
  intrahash = {f46601cf8b13d39d1378af0d79438b12},
  keywords = {},
  publisher = {The MIT Press},
  timestamp = {2019-07-13T10:11:53.000+0200},
  title = {Reinforcement Learning: An Introduction},
  url = {http://incompleteideas.net/book/the-book-2nd.html},
  year = {2018}
}

